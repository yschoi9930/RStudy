library(RJSONIO)
json_data <- fromJSON(raw_text_json)
json_data
test <- json_data[[1]]$nf
search_url <- function(x) {
data <- x$nf
data[names(data) %in% "imgur"]
}
rst <- search_url(test)
data <- test$nf
data[names(data) %in% "imgur"]
test <- json_data[[1]]
search_url <- function(x) {
data <- test$nf
data[names(data) %in% "imgur"]
}
rst <- search_url(test)
rst
img_url <- sapply(json_data,search_url)
img_url
json_data <- fromJSON(raw_text_json)
test <- json_data[[1]]
search_url <- function(x) {
data <- test$nf
data[names(data) %in% "imgur"]
}
img_url <- sapply(json_data,search_url)
img_url
download.file(img_url[1],'car_text.jpg',mode='wb')
# 폴더생성
keyword <- 'car'
dir.create(paste0('C:/Rstudy',keyword))
dir.create(paste0('C:/Rstudy/',keyword))
search_url <- function(x) {
data <- x$nf
data[names(data) %in% "imgur"]
}
img_url <- sapply(json_data,search_url)
img_url
for (i in 1:length(img_url)) {
file_name <- paste0((keyword,i,'.jpg'))
download.file(img_url[i], file_name, mode='wb')
}
# 폴더생성
keyword <- 'car'
dir.create(paste0('C:/Rstudy/',keyword))
setwd(paste0('C:/Rstudy/',keyword))
for (i in 1:length(img_url)) {
file_name <- paste0((keyword,i,'.jpg'))
download.file(img_url[i], file_name, mode='wb')
}
for (i in 1:length(img_url)){
file_name <- paste0((keyword,i,'.jpg'))
download.file(img_url[i], file_name, mode='wb')
}
file_name <- paste0(keyword,i,'.jpg')
for (i in 1:length(img_url)){
file_name <- paste0(keyword,i,'.jpg')
download.file(img_url[i], file_name, mode='wb')
}
## httr 패키지 - 요청, 응답시 사용 패키지
library(httr)
# 기본 URL
urlstr <- 'https://openapi.naver.com/v1/search/blog.xml'
searchstr <- paste0('query=',keyword)
# url인코딩
searchstr <- URLencode(serchstr)
# url인코딩
searchstr <- URLencode(searchstr)
searchstr
# 검색어 설정
keyword <- '자동차'
searchstr <- paste0('query=',keyword)
# 한글 인코딩
searchstr <- iconv(searchstr, to='UTF-8')
# url인코딩
searchstr <- URLencode(searchstr)
searchstr
# 나머지 요청변수 설정
req_str <- '&display=50&start=1&sort=sim'
# 요청변수 조립
req_URL <- paste0(urlstr,searchstr,req_str)
req_URL
# 기본 URL
urlstr <- 'https://openapi.naver.com/v1/search/blog.xml?'
# 한글 인코딩
searchstr <- iconv(searchstr, to='UTF-8')
# 요청변수 조립
req_URL <- paste0(urlstr,searchstr,req_str)
req_URL
# headers 변수 설정
clientID <- "dylL4vaALt3jr39dZW4c"
clientpw <- '6IcFbl92ar'
# 호출 : GET(url) 함수 이용 - 헤더데이터는 add_headers(변수,변수)
apiRest <- GET(req_URL,
add_headers('X-Naver-Client-Id' = clientID,
'X-Naver-Client-Secret' = clientpw))
apiRest
View(apiRest)
apiRest$content
result <- rawtochar(apiRest$content) # binary data -> 문자로
result <- rawTOChar(apiRest$content) # binary data -> 문자로
result <- rawToChar(apiRest$content) # binary data -> 문자로
result
Encoding(result) <- 'UTF-8'
result
length(result)
# 데이터 파싱
# xml 데이터 -> xml2 패키지 사용
library(xml2)
# 데이터 읽어오기
content <- read_html(apiRest)
content
# 데이터 읽어오기
content <- read_xml(apiRest)
content
con_child <- xml_child(content)
con_child
items <- xml_find_all(con_child, 'item')
items
View(items)
items[1]
xml_find_all(items[1],'./*')
test <- xml_find_all(items[1],'./*')
class(test)
test[1]
items # 50개 들어와있음
items[1]
items[1][[1]]
items[1][[2]]
test
xml_name(test)
test
xml_text(test)
srch <- function(x) {
temp <- xml_find_all(items[x],'./*')
td_raw <- tibble(
key <- xml_name(temp)
value <- xml_text(temp)
)
return(td_raw)
}
srch <- function(x) {
temp <- xml_find_all(items[x],'./*')
td_raw <- tibble(
key <- xml_name(temp),
value <- xml_text(temp)
)
return(td_raw)
}
td <- srch(text[1])
library(dplyr)
srch <- function(x) {
temp <- xml_find_all(items[x],'./*')
td_raw <- tibble(
key <- xml_name(temp),
value <- xml_text(temp)
)
return(td_raw)
}
td <- srch(text[1])
srch <- function(x) {
temp <- xml_find_all(x,'./*')
td_raw <- tibble(
key <- xml_name(temp),
value <- xml_text(temp)
)
return(td_raw)
}
td <- srch(text[1])
td <- srch(test[1])
td
srch <- function(x) {
temp <- xml_find_all(x,'./*')
td_raw <- tibble(
key = xml_name(temp),
value = xml_text(temp)
)
return(td_raw)
}
td <- srch(test[1])
td
td <- srch(item[1])
td <- srch(items[1])
td
ld <- lapply(1:length(items),
function(n) {
temp <- xml_find_all(n,'./*')
td_raw <- tibble(
key = xml_name(temp),
value = xml_text(temp)
)
return(td_raw)
})
items <- xml_find_all(con_child, 'item')
items # 50개 들어와있음
ld <- lapply(1:length(items),
function(n) {
temp <- xml_find_all(n,'./*')
td_raw <- tibble(
key = xml_name(temp),
value = xml_text(temp)
)
return(td_raw)
})
temp <- xml_find_all(items[n],'./*')
ld <- lapply(1:length(items),
function(n) {
temp <- xml_find_all(items[n],'./*')
td_raw <- tibble(
key = xml_name(temp),
value = xml_text(temp)
)
return(td_raw)
})
ld
bind_td <- bind_rows(ld)
bind_td
library(reshape2)
spread(bind_td,key,value)
library(reshape)
spread(bind_td,key,value)
library(dplyr)
spread(bind_td,key,value)
library(tidyr)
spread(bind_td,key,value)
spread(bind_td,key,value)
bind_td <- bind_rows(ld) # 리스트 요소들을 행결합
bind_td
View(bind_td)
spread(bind_td,key,value)
srch <- function(x) {
temp <- xml_find_all(x,'./*')
td_raw <- tibble(
key = xml_name(temp),
value = xml_text(temp)
)
return(td_raw)
}
td <- srch(items[1])
td
ld <- lapply(1:length(items),
function(n) {
temp <- xml_find_all(items[n],'./*')
td_raw <- tibble(
key = xml_name(temp),
value = xml_text(temp)
)
return(td_raw)
})
ld
bind_td <- bind_rows(ld) # 리스트 요소들을 행결합
View(bind_td)
spread(bind_td,key,value)
View(bind_td)
items <- xml_find_all(con_child, 'item')
ld <- lapply(1:length(items),
function(n) {
temp <- xml_find_all(items[n],'./*')
td_raw <- tibble(
id = n,
key = xml_name(temp),
value = xml_text(temp)
)
return(td_raw)
})
bind_td <- bind_rows(ld) # 리스트 요소들을 행결합
spread(bind_td,key,value)
keyword <- '브레이브걸스'
search <- paste0('query=',keyword)
search <- paste0('query=',keyword) %>% iconv(,'UTF-8')
search
search <- paste0('query=',keyword) %>% iconv(,to='UTF-8')
search
search <- paste0('query=',keyword)
search <- iconv(search,to='UTF-8')
search
encoding(search)
encoding(search)
Encoding(search)
URLencode(search)
search <- URLencode(search)
req <- '&display=200&start=1&sort=sim'
URL <- paste0(search,req)
URL
URL <- paste0(base,search,req)
base <- 'https://openapi.naver.com/v1/search/blog.xml?'
URL <- paste0(base,search,req)
URL
clientID <- "dylL4vaALt3jr39dZW4c"
clientpw <- '6IcFbl92ar'
api <- GET(URL,
add_headers('X-Naver-Client-Id' = clientID,
'X-Naver-Client-Secret' = clientpw))
api
base <- 'https://openapi.naver.com/v1/search/image.xml?'
keyword <- '브레이브걸스'
search <- paste0('query=',keyword)
search <- iconv(search,to='UTF-8')
search
search <- URLencode(search)
req <- '&display=200&start=1&sort=sim'
URL <- paste0(base,search,req)
URL
clientID <- "dylL4vaALt3jr39dZW4c"
clientpw <- '6IcFbl92ar'
api <- GET(URL,
add_headers('X-Naver-Client-Id' = clientID,
'X-Naver-Client-Secret' = clientpw))
api
# 기본 URL
urlstr <- 'https://openapi.naver.com/v1/search/blog.xml?'
# 검색어 설정
keyword <- '자동차'
searchstr <- paste0('query=',keyword)
# 한글 인코딩
searchstr <- iconv(searchstr, to='UTF-8')
# url인코딩
searchstr <- URLencode(searchstr)
searchstr
req_URL
URL
api <- GET(URL,
add_headers('X-Naver-Client-Id' = clientID,
'X-Naver-Client-Secret' = clientpw))
api
api$content
result <- rawToChar(api$content)
result
Encoding(result)
URL
clientID <- "dylL4vaALt3jr39dZW4c"
clientpw <- '6IcFbl92ar'
api
req <- '&display=100&start=1&sort=sim'
URL <- paste0(base,search,req)
URL
clientID <- "dylL4vaALt3jr39dZW4c"
clientpw <- '6IcFbl92ar'
api <- GET(URL,
add_headers('X-Naver-Client-Id' = clientID,
'X-Naver-Client-Secret' = clientpw))
api
api$content
result <- rawToChar(api$content)
result
Encoding(result)
api$content
api <- GET(URL,
add_headers('X-Naver-Client-Id' = clientID,
'X-Naver-Client-Secret' = clientpw))
api
api$content
Encoding(result)
result <- rawToChar(api$content)
result
Encoding(result) <- 'UTF-8'
result
library(xml2)
xml_r <- read_xml(result)
xml_r
child <- con_child(xml_r)
child <- xml_child(xml_r)
child
img_items <- xml_find_all(child,'items')
img_items
img_items[1]
child
img_items <- xml_find_all(child,'item')
img_items[1]
img_items[[1]]
img_items[1]
View(img_items)
child <- xml_child(xml_r)
child
img_items <- xml_find_all(child,'item')
img_items[1]
img_items[[1]]
img_items[[1]][2]
img_items[[[2]]]
img_items[1]
img_items[[1]]
img_items[[1]][3]
search <- functtion(x) {
temp <- xml_find_all(x,'./*')
td_raw <- tibble(key = xml_name(temp),
value = xml_text(temp))
return(td_raw)
}
search <- functtion(x) {
temp <- xml_find_all(x,'./*')
td_raw <- tibble(key = xml_name(temp),
value = xml_text(temp))
return(td_raw)
}
search <- functtion(x) {
temp <- xml_find_all(x,'./*')
td_raw <- tibble(key = xml_name(temp),
value = xml_text(temp))
return(td_raw)
}
library(dplyr)
search <- functtion(x) {
temp <- xml_find_all(x,'./*')
td_raw <- tibble(key = xml_name(temp),
value = xml_text(temp))
return(td_raw)
}
library(tplyr)
library(tidyr)
search <- functtion(x) {
temp <- xml_find_all(x,'./*')
td_raw <- tibble(key = xml_name(temp),
value = xml_text(temp))
return(td_raw)
}
srch <- function(x) {
temp <- xml_find_all(x,'./*')
td_raw <- tibble(key = xml_name(temp),
value = xml_text(temp))
return(td_raw)
}
search <- function(x) {
temp <- xml_find_all(x,'./*')
td_raw <- tibble(key = xml_name(temp),
value = xml_text(temp))
return(td_raw)
}
length(img_items)
td <- lapply(1:100, function(n) {
temp <- xml_find_all(items[n],'./*')
td_raw <- tibble(
id = n,
key = xml_name(temp),
value = xml_text(temp)
)
return(td_raw)
}))
td <- lapply(1:100, function(n) {
temp <- xml_find_all(items[n],'./*')
td_raw <- tibble(
id = n,
key = xml_name(temp),
value = xml_text(temp)
)
return(td_raw)
})
search(item[1])
search(img_item[1])
search(img_items[1])
td <- lapply(1:100, function(n) {
temp <- xml_find_all(img_items[n],'./*')
td_raw <- tibble(
id = n,
key = xml_name(temp),
value = xml_text(temp)
)
return(td_raw)
})
td
td <- bind_rows(td)
td
td <- spread(td,key,value)
td
View(td)
td <- td[2:]
td <- td[,2:]
td[,2]
ncol(td)
td <- td[,2:6]
VieW(td)
VieW(td)
View(td)
img_url
td[4,1]
img_link <- td[,4]
img_link
img_link <- td[,1]
img_link
setwd()
pwd()
download.file(img_link[1],'a.jpg',mode='wb')
img_link <- td[,4]
img_link
download.file(img_link[1],'a.jpg',mode='wb')
img_url
img_link
str(img_link)
class(img_link)
class(img_link[1])
typeof(img_link[1])
img_link
download.file('http://imgnews.naver.net/image/117/2016/02/16/201602161606551134_2_99_20160216182405.jpg
','a.jpg',mode='wb')
img_url <- paste0(",img_link[1],")
img_url
img_url <- paste0(\",img_link[1],\")
img_url
for (i in 1:length(img_url)){
img_url <- paste0(",img_link[i],")
file_name <- paste0(keyword,i,'.jpg')
download.file(img_url[i], file_name, mode='wb')
}
img_url <- paste0('"',img_link[1],"'")
img_url
img_link
img_link[1]
img_link[[1]
img_link[[1]]
img_link[[1]]
img_link <- img_link[[1]]
img_link[1]
